{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as cp\n",
    "import numpy as np\n",
    "\n",
    "X, y = cp.load(open('winequality-white.pickle','rb'))\n",
    "\n",
    "N, num_features = X.shape\n",
    "N_train = int(0.8 * N)\n",
    "N_test = N - N_train\n",
    "X_train = X[:N_train]\n",
    "y_train = y[:N_train]\n",
    "X_test = X[N_train:]\n",
    "y_test = y[N_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handin 1 : \n",
    "Make a bar chart showing the distribution of y values appearing in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 7 artists>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff2614b4780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import itemfreq\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "%matplotlib inline\n",
    "plt.bar(unique, counts, align='center', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Handin 2 : Report the mean squared error, i.e., the average of the squared residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.87876467586\n",
      "[-0.87876468  0.12123532 -0.87876468  0.12123532 -0.87876468 -0.87876468\n",
      " -0.87876468  1.12123532 -0.87876468  0.12123532  1.12123532 -0.87876468\n",
      "  0.12123532  1.12123532  0.12123532 -0.87876468 -0.87876468 -0.87876468\n",
      "  0.12123532  1.12123532  1.12123532  0.12123532  1.12123532  1.12123532\n",
      "  2.12123532 -2.87876468 -0.87876468  0.12123532  0.12123532 -0.87876468\n",
      " -1.87876468  1.12123532  0.12123532  0.12123532  0.12123532  1.12123532\n",
      "  0.12123532 -0.87876468  1.12123532 -0.87876468  1.12123532  1.12123532\n",
      "  0.12123532 -0.87876468 -0.87876468  1.12123532 -0.87876468  1.12123532\n",
      " -1.87876468  0.12123532  0.12123532  0.12123532  0.12123532  2.12123532\n",
      "  0.12123532  1.12123532 -0.87876468  0.12123532  1.12123532  0.12123532\n",
      "  0.12123532  0.12123532  0.12123532  0.12123532  0.12123532  0.12123532\n",
      "  0.12123532  1.12123532  0.12123532  0.12123532 -0.87876468  1.12123532\n",
      " -0.87876468  1.12123532  0.12123532  1.12123532  1.12123532  0.12123532\n",
      " -0.87876468  0.12123532 -1.87876468  1.12123532  1.12123532  0.12123532\n",
      " -0.87876468  0.12123532  0.12123532  0.12123532  1.12123532 -0.87876468\n",
      " -1.87876468  1.12123532  0.12123532 -0.87876468 -0.87876468  0.12123532\n",
      "  0.12123532  0.12123532  1.12123532  1.12123532  0.12123532  1.12123532\n",
      "  0.12123532  1.12123532  1.12123532  0.12123532 -0.87876468 -0.87876468\n",
      " -0.87876468 -0.87876468 -0.87876468  2.12123532  0.12123532  0.12123532\n",
      "  0.12123532 -0.87876468  0.12123532  0.12123532  0.12123532  0.12123532\n",
      "  0.12123532  0.12123532 -0.87876468 -0.87876468  0.12123532 -0.87876468\n",
      "  1.12123532  0.12123532  0.12123532  2.12123532  0.12123532  0.12123532\n",
      " -1.87876468  0.12123532  1.12123532  0.12123532  0.12123532  0.12123532\n",
      "  0.12123532  0.12123532  0.12123532  1.12123532 -0.87876468  0.12123532\n",
      "  0.12123532  2.12123532 -0.87876468  0.12123532 -0.87876468  0.12123532\n",
      "  0.12123532  0.12123532 -0.87876468  0.12123532  1.12123532 -0.87876468\n",
      " -0.87876468 -0.87876468 -1.87876468  1.12123532  0.12123532  1.12123532\n",
      " -0.87876468  1.12123532 -0.87876468  0.12123532  0.12123532 -0.87876468\n",
      " -0.87876468 -0.87876468 -1.87876468  1.12123532  0.12123532  0.12123532\n",
      "  1.12123532  0.12123532  0.12123532  1.12123532  0.12123532  0.12123532\n",
      " -0.87876468  1.12123532  0.12123532  2.12123532 -0.87876468  0.12123532\n",
      "  0.12123532 -0.87876468 -0.87876468 -0.87876468  0.12123532 -0.87876468\n",
      " -0.87876468  1.12123532 -0.87876468  1.12123532 -0.87876468  0.12123532\n",
      "  0.12123532 -0.87876468  1.12123532  2.12123532  1.12123532  0.12123532\n",
      "  0.12123532  1.12123532  0.12123532  2.12123532  1.12123532  1.12123532\n",
      " -0.87876468  0.12123532 -2.87876468 -0.87876468  0.12123532  0.12123532\n",
      "  0.12123532  0.12123532 -0.87876468  0.12123532  0.12123532  2.12123532\n",
      "  1.12123532  0.12123532  0.12123532  0.12123532  0.12123532  2.12123532\n",
      "  1.12123532  0.12123532  2.12123532  0.12123532  0.12123532 -0.87876468\n",
      "  0.12123532  0.12123532  0.12123532  1.12123532  0.12123532 -0.87876468\n",
      "  0.12123532  0.12123532  1.12123532 -0.87876468  1.12123532  0.12123532\n",
      "  0.12123532  0.12123532 -2.87876468  0.12123532 -0.87876468  0.12123532\n",
      "  0.12123532 -0.87876468  1.12123532  0.12123532 -0.87876468  0.12123532\n",
      "  1.12123532  0.12123532  1.12123532  0.12123532  0.12123532  1.12123532\n",
      "  1.12123532  1.12123532 -0.87876468 -0.87876468  0.12123532  0.12123532\n",
      "  1.12123532 -0.87876468  0.12123532  0.12123532 -0.87876468  1.12123532\n",
      "  0.12123532 -0.87876468 -0.87876468  1.12123532  0.12123532  0.12123532\n",
      "  0.12123532 -0.87876468 -0.87876468 -2.87876468 -0.87876468  0.12123532\n",
      "  0.12123532  0.12123532 -0.87876468  0.12123532  0.12123532  1.12123532\n",
      "  0.12123532 -1.87876468  0.12123532 -0.87876468 -0.87876468 -0.87876468\n",
      "  0.12123532  0.12123532  0.12123532  1.12123532  0.12123532  1.12123532\n",
      "  1.12123532  2.12123532 -0.87876468 -2.87876468 -0.87876468  1.12123532\n",
      "  0.12123532  1.12123532  0.12123532  1.12123532  0.12123532  2.12123532\n",
      "  0.12123532  1.12123532  0.12123532  0.12123532  0.12123532  1.12123532\n",
      " -0.87876468  0.12123532 -0.87876468  1.12123532  0.12123532  2.12123532\n",
      "  2.12123532 -0.87876468  0.12123532  0.12123532  0.12123532  0.12123532\n",
      " -0.87876468  0.12123532 -0.87876468  0.12123532 -0.87876468 -0.87876468\n",
      "  0.12123532  1.12123532  0.12123532 -0.87876468 -0.87876468 -0.87876468\n",
      " -0.87876468 -0.87876468  0.12123532  0.12123532  3.12123532  0.12123532\n",
      " -0.87876468 -0.87876468 -0.87876468  0.12123532  1.12123532  1.12123532\n",
      " -0.87876468  0.12123532  0.12123532  1.12123532  0.12123532  1.12123532\n",
      "  0.12123532  0.12123532  0.12123532  1.12123532 -0.87876468  0.12123532\n",
      " -0.87876468  0.12123532  0.12123532 -0.87876468  1.12123532  0.12123532\n",
      "  0.12123532  0.12123532 -0.87876468 -0.87876468  0.12123532 -0.87876468\n",
      " -1.87876468  0.12123532  0.12123532 -0.87876468  0.12123532 -0.87876468\n",
      " -0.87876468  1.12123532  0.12123532  0.12123532  0.12123532 -0.87876468\n",
      "  0.12123532 -0.87876468  2.12123532 -0.87876468 -0.87876468  0.12123532\n",
      " -0.87876468  1.12123532  0.12123532 -0.87876468  1.12123532 -0.87876468\n",
      "  0.12123532  0.12123532 -0.87876468 -0.87876468  0.12123532 -0.87876468\n",
      "  0.12123532 -0.87876468  1.12123532  1.12123532 -0.87876468 -0.87876468\n",
      "  0.12123532 -0.87876468 -1.87876468  1.12123532  0.12123532  0.12123532\n",
      " -0.87876468 -0.87876468  0.12123532 -0.87876468  1.12123532 -0.87876468\n",
      " -0.87876468  0.12123532  0.12123532  0.12123532 -1.87876468  0.12123532\n",
      "  0.12123532  0.12123532  0.12123532 -0.87876468 -0.87876468  0.12123532\n",
      "  0.12123532  0.12123532  0.12123532  0.12123532  0.12123532 -0.87876468\n",
      " -0.87876468 -0.87876468  0.12123532  0.12123532  1.12123532 -0.87876468\n",
      " -0.87876468  1.12123532  0.12123532  1.12123532  1.12123532  0.12123532\n",
      " -0.87876468  0.12123532  0.12123532  0.12123532  0.12123532  0.12123532\n",
      "  1.12123532  0.12123532 -0.87876468  1.12123532 -0.87876468  0.12123532\n",
      " -1.87876468 -0.87876468 -1.87876468 -0.87876468  1.12123532 -1.87876468\n",
      " -1.87876468  1.12123532  0.12123532  1.12123532  0.12123532  0.12123532\n",
      "  0.12123532  1.12123532  1.12123532  0.12123532  0.12123532 -0.87876468\n",
      " -0.87876468  0.12123532  0.12123532 -1.87876468  0.12123532 -0.87876468\n",
      "  0.12123532 -1.87876468  0.12123532  0.12123532  0.12123532  0.12123532\n",
      "  2.12123532  1.12123532  0.12123532  0.12123532  1.12123532  2.12123532\n",
      "  0.12123532  1.12123532  1.12123532  0.12123532 -0.87876468  1.12123532\n",
      " -0.87876468  0.12123532  0.12123532  0.12123532  0.12123532 -0.87876468\n",
      "  0.12123532  0.12123532 -0.87876468  0.12123532 -0.87876468  0.12123532\n",
      "  1.12123532  1.12123532 -0.87876468  0.12123532  0.12123532 -0.87876468\n",
      " -0.87876468  0.12123532 -0.87876468  0.12123532 -0.87876468 -0.87876468\n",
      " -0.87876468 -1.87876468  1.12123532  0.12123532  1.12123532  0.12123532\n",
      " -0.87876468 -0.87876468  0.12123532 -0.87876468 -0.87876468 -0.87876468\n",
      "  1.12123532  0.12123532  0.12123532  0.12123532 -0.87876468  0.12123532\n",
      "  0.12123532  0.12123532  0.12123532 -1.87876468  0.12123532  1.12123532\n",
      "  0.12123532  0.12123532 -0.87876468  1.12123532  0.12123532 -0.87876468\n",
      " -0.87876468  0.12123532 -0.87876468  0.12123532  0.12123532  0.12123532\n",
      "  0.12123532 -0.87876468 -0.87876468  1.12123532  0.12123532 -0.87876468\n",
      " -0.87876468  1.12123532 -1.87876468  1.12123532 -0.87876468  0.12123532\n",
      " -0.87876468  0.12123532 -0.87876468  0.12123532  1.12123532  1.12123532\n",
      "  0.12123532 -0.87876468 -0.87876468 -0.87876468  0.12123532  1.12123532\n",
      " -0.87876468  0.12123532  0.12123532  1.12123532  0.12123532 -0.87876468\n",
      "  0.12123532  0.12123532  0.12123532 -2.87876468 -0.87876468  0.12123532\n",
      " -0.87876468  2.12123532  0.12123532  0.12123532 -0.87876468  0.12123532\n",
      " -0.87876468  0.12123532 -0.87876468  0.12123532  1.12123532 -0.87876468\n",
      " -0.87876468  0.12123532 -0.87876468 -0.87876468 -0.87876468  0.12123532\n",
      "  0.12123532  1.12123532 -0.87876468  1.12123532  1.12123532  0.12123532\n",
      "  0.12123532  0.12123532  1.12123532  0.12123532  1.12123532  1.12123532\n",
      " -0.87876468 -0.87876468  1.12123532  1.12123532  2.12123532 -0.87876468\n",
      "  0.12123532  0.12123532  0.12123532  0.12123532  0.12123532  0.12123532\n",
      "  0.12123532 -0.87876468  0.12123532  1.12123532  2.12123532  1.12123532\n",
      "  0.12123532  0.12123532  1.12123532 -0.87876468 -0.87876468  0.12123532\n",
      "  0.12123532  1.12123532  1.12123532  0.12123532  1.12123532  1.12123532\n",
      " -0.87876468  0.12123532  0.12123532 -0.87876468  0.12123532 -0.87876468\n",
      " -0.87876468 -0.87876468  1.12123532  3.12123532  1.12123532  0.12123532\n",
      "  0.12123532  0.12123532  0.12123532 -0.87876468 -0.87876468  1.12123532\n",
      "  0.12123532 -1.87876468 -1.87876468 -1.87876468  0.12123532  1.12123532\n",
      "  0.12123532  0.12123532  0.12123532  0.12123532  0.12123532 -0.87876468\n",
      " -0.87876468 -1.87876468 -0.87876468 -0.87876468  0.12123532 -0.87876468\n",
      " -0.87876468  1.12123532  0.12123532  1.12123532  2.12123532 -0.87876468\n",
      "  1.12123532 -0.87876468  0.12123532 -0.87876468 -1.87876468  0.12123532\n",
      "  1.12123532  1.12123532 -0.87876468 -0.87876468  0.12123532 -0.87876468\n",
      " -0.87876468 -0.87876468 -0.87876468 -0.87876468  0.12123532 -0.87876468\n",
      "  0.12123532  0.12123532  1.12123532  0.12123532  0.12123532  0.12123532\n",
      " -0.87876468 -0.87876468  1.12123532  0.12123532  0.12123532  0.12123532\n",
      "  0.12123532 -0.87876468  1.12123532 -1.87876468  0.12123532  2.12123532\n",
      "  0.12123532  0.12123532  0.12123532 -0.87876468  0.12123532  0.12123532\n",
      "  1.12123532  1.12123532 -0.87876468 -0.87876468  0.12123532 -0.87876468\n",
      " -0.87876468 -1.87876468  1.12123532  0.12123532  1.12123532  0.12123532\n",
      " -0.87876468  0.12123532  0.12123532  0.12123532 -0.87876468  0.12123532\n",
      "  0.12123532 -1.87876468  1.12123532 -0.87876468  1.12123532  1.12123532\n",
      "  0.12123532  0.12123532  1.12123532  0.12123532  1.12123532  0.12123532\n",
      " -0.87876468 -0.87876468  0.12123532  1.12123532 -0.87876468  1.12123532\n",
      " -0.87876468  0.12123532 -1.87876468  0.12123532  0.12123532 -0.87876468\n",
      " -0.87876468 -0.87876468  0.12123532  0.12123532  0.12123532  0.12123532\n",
      " -0.87876468 -0.87876468  1.12123532 -0.87876468  0.12123532  1.12123532\n",
      "  1.12123532  1.12123532  1.12123532  1.12123532 -0.87876468  0.12123532\n",
      " -1.87876468  0.12123532  1.12123532  0.12123532  1.12123532  0.12123532\n",
      " -0.87876468 -0.87876468  0.12123532  0.12123532 -0.87876468  1.12123532\n",
      "  1.12123532 -0.87876468 -0.87876468 -0.87876468  0.12123532 -0.87876468\n",
      "  0.12123532 -0.87876468  0.12123532 -0.87876468  2.12123532  0.12123532\n",
      "  1.12123532 -1.87876468  1.12123532  0.12123532  0.12123532  2.12123532\n",
      " -0.87876468 -0.87876468 -0.87876468 -0.87876468  0.12123532 -0.87876468\n",
      " -0.87876468  0.12123532  0.12123532  0.12123532  1.12123532  1.12123532\n",
      " -0.87876468  0.12123532  0.12123532  0.12123532  0.12123532  0.12123532\n",
      "  0.12123532 -0.87876468 -0.87876468  1.12123532  0.12123532 -0.87876468\n",
      "  2.12123532 -0.87876468  0.12123532  2.12123532  0.12123532  0.12123532\n",
      " -0.87876468  1.12123532  2.12123532 -0.87876468 -0.87876468 -0.87876468\n",
      "  0.12123532  0.12123532 -0.87876468 -0.87876468  2.12123532  0.12123532\n",
      "  1.12123532 -0.87876468  1.12123532  0.12123532  0.12123532  1.12123532\n",
      "  1.12123532  0.12123532 -0.87876468  1.12123532  1.12123532 -1.87876468\n",
      " -1.87876468  0.12123532  0.12123532  0.12123532  0.12123532  0.12123532\n",
      "  0.12123532 -0.87876468  0.12123532  2.12123532  1.12123532  0.12123532\n",
      "  0.12123532  0.12123532  0.12123532 -0.87876468  0.12123532  0.12123532\n",
      "  1.12123532  0.12123532 -0.87876468  0.12123532 -0.87876468  0.12123532\n",
      "  1.12123532  2.12123532  1.12123532  0.12123532 -0.87876468 -0.87876468\n",
      " -0.87876468 -0.87876468 -0.87876468 -0.87876468  0.12123532  0.12123532\n",
      "  0.12123532 -0.87876468  1.12123532 -0.87876468  0.12123532  0.12123532\n",
      " -0.87876468 -0.87876468 -0.87876468 -0.87876468  1.12123532  1.12123532\n",
      "  1.12123532 -1.87876468  1.12123532 -0.87876468  0.12123532 -0.87876468\n",
      " -0.87876468 -0.87876468  1.12123532  0.12123532 -0.87876468 -0.87876468\n",
      "  0.12123532  1.12123532  0.12123532 -0.87876468  0.12123532 -0.87876468\n",
      " -0.87876468 -0.87876468 -0.87876468 -0.87876468  0.12123532  0.12123532\n",
      "  0.12123532 -0.87876468  0.12123532  0.12123532  0.12123532  0.12123532\n",
      "  0.12123532  0.12123532]\n",
      "Naive mse 0.776777\n",
      "Naive mse_test 0.813857\n"
     ]
    }
   ],
   "source": [
    "average = np.mean(y_train)\n",
    "mse = np.mean((y_train - average)**2)\n",
    "mse_test = np.mean((y_test- average)**2)\n",
    "print (\"Naive mse %f\"%mse)\n",
    "print (\"Naive mse_test %f\"%mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_mean = [] \n",
    "feature_std = [] \n",
    "for col in range(num_features):\n",
    "    feature_val = X_train[:,col]\n",
    "    mean = np.mean(feature_val)\n",
    "    std = np.std(feature_val)\n",
    "    std_feature = (feature_val - mean)/std \n",
    "    feature_mean.append(mean)\n",
    "    feature_std.append(std)\n",
    "    X_train[:,col] = std_feature \n",
    "    test_feature_val = X_test[:,col]\n",
    "    std_test = (test_feature_val - mean)/std \n",
    "    X_test[:,col] = std_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closed-form Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training data : 0.564000\n",
      "MSE for test data : 0.560729\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import inv\n",
    "ones = np.ones(len(X_train))\n",
    "X_train_appended = np.column_stack((ones,X_train))\n",
    "X_transpose = np.transpose(X_train_appended)\n",
    "w = np.dot(np.dot(inv(np.dot(X_transpose, X_train_appended)),X_transpose),y_train)\n",
    "y_predict = np.dot(X_train_appended,w)\n",
    "mse = np.average((y_train - y_predict)**2)\n",
    "print (\"MSE for training data : %f\"%mse)\n",
    "X_test_appended = np.column_stack((np.ones(len(X_test)),X_test))\n",
    "y_test_predict =  np.dot(X_test_appended,w)\n",
    "mse_test = np.average((y_test - y_test_predict)**2)\n",
    "print (\"MSE for test data : %f\"%mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double Checking with sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for training data: 0.56\n",
      "Mean squared error for test data: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "#print('Coefficients: \\n', regr.coef_)\n",
    "predict = regr.predict(X_train)\n",
    "print(\"Mean squared error for training data: %.2f\"\n",
    "      % mean_squared_error(y_train,predict ))\n",
    "predict_test = regr.predict(X_test)\n",
    "print(\"Mean squared error for test data: %.2f\"\n",
    "      % mean_squared_error(y_test,predict_test ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Handin 4: Report the learning curves plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff2680a1588>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff26ef2d860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = 20 \n",
    "max_datasets = 600\n",
    "datapoints = []\n",
    "training_error = []\n",
    "testing_error = [] \n",
    "\n",
    "while (datasets <600): \n",
    "    X_train_batch = X_train_appended[:datasets,:]\n",
    "    y_train_batch = y_train[:datasets]\n",
    "    X_transpose = np.transpose(X_train_batch)\n",
    "    w = np.dot(np.dot(inv(np.dot(X_transpose, X_train_batch)),X_transpose),y_train_batch)\n",
    "    y_predict = np.dot(X_train_batch,w)\n",
    "    mse = np.average((y_train_batch - y_predict)**2)\n",
    "    training_error.append(mse)\n",
    "    X_test = X_test_appended\n",
    "    y_test_predict =  np.dot(X_test,w)\n",
    "    mse_test = np.average((y_test - y_test_predict)**2)\n",
    "    testing_error.append(mse_test)\n",
    "    datasets = datasets + 20 \n",
    "    datapoints.append(datasets)\n",
    "    \n",
    "%matplotlib inline\n",
    "plt.plot(datapoints,training_error)\n",
    "plt.plot(datapoints,testing_error)\n",
    "\n",
    "plt.legend(['Training Error', 'Testing Error'], loc='upper right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the model is not underfitting. After getting around 250 data points the training error and testing error plateaus and that's the amount of data needed to get the optimal test error.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with poly degree 2\n",
      "mse for ridge regression with optimal lambda 1.000000 : 0.512589\n",
      "mse for lasso regression with optimal lambda 0.010000 : 0.527511\n",
      "working with poly degree 3\n",
      "mse for ridge regression with optimal lambda 100.000000 : 0.599301\n",
      "mse for lasso regression with optimal lambda 0.010000 : 0.514302\n",
      "working with poly degree 4\n",
      "mse for ridge regression with optimal lambda 100.000000 : 1.087639\n",
      "mse for lasso regression with optimal lambda 0.010000 : 0.521606\n",
      "working with poly degree 5\n",
      "mse for ridge regression with optimal lambda 100.000000 : 1.597427\n",
      "mse for lasso regression with optimal lambda 0.010000 : 0.508657\n",
      "optimal for ridge is degre 2 with mse 0.512589\n",
      "optimal for lasso is degre 5 with mse 0.508657\n"
     ]
    }
   ],
   "source": [
    "lambda_list = [0.01,0.1,1,10,100 ]\n",
    "\n",
    "X_train_new = X[:int(0.6*N)]\n",
    "X_validation = X[int(0.6*N):int(0.8*N)]\n",
    "y_train_new = y[:int(0.6*N)]\n",
    "y_validation = y[int(0.6*N):int(0.8*N)]\n",
    "X_train = X[:int(0.8*N)]\n",
    "y_train = y[:int(0.8*N)]\n",
    "X_test = X[int(0.8*N):]\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "optimal_ridges = [] \n",
    "optimal_lassos = []\n",
    "poly_degrees = [2,3,4,5]\n",
    "for poly_degree in poly_degrees: \n",
    "    print ('working with poly degree %d'%poly_degree)\n",
    "    poly = PolynomialFeatures(poly_degree)\n",
    "    X_train_new_poly = poly.fit_transform(X_train_new)\n",
    "    X_validation_poly = poly.transform(X_validation)\n",
    "    X_train_poly = poly.transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_transform = scaler.fit_transform(X_train_new_poly)\n",
    "    X_validation_transform = scaler.transform(X_validation_poly)\n",
    "    X_train_transform = scaler.transform(X_train_poly)\n",
    "    X_test_transform = scaler.transform(X_test_poly)\n",
    "\n",
    "    coefs_ridge = []\n",
    "    ridge_mse_list = [] \n",
    "    for lam in lambda_list : \n",
    "        ridge = Ridge(alpha=lam)\n",
    "        ridge.fit(X_transform, y_train_new) \n",
    "        y_validation_predict = ridge.predict(X_validation_transform)\n",
    "        coefs_ridge.append(ridge.coef_)\n",
    "        mse = mean_squared_error(y_validation,y_validation_predict)\n",
    "        ridge_mse_list.append(mse)\n",
    "     #   print ('lambda %f with mse %f '%(lam, mse))\n",
    "\n",
    "    optimal_lam_ridge = lambda_list[ridge_mse_list.index(min(ridge_mse_list))]\n",
    "\n",
    "    coefs_lasso = []\n",
    "    lasso_mse_list = [] \n",
    "    for lam in lambda_list : \n",
    "        lasso = Lasso(alpha=lam)\n",
    "        lasso.fit(X_transform, y_train_new) \n",
    "        y_validation_predict = lasso.predict(X_validation_transform)\n",
    "        coefs_lasso.append(lasso.coef_)\n",
    "        mse = mean_squared_error(y_validation,y_validation_predict)\n",
    "        lasso_mse_list.append(mse)\n",
    "    #    print ('lambda %f with mse %f '%(lam, mse))\n",
    "\n",
    "    optimal_lam_lasso = lambda_list[lasso_mse_list.index(min(lasso_mse_list))]\n",
    "\n",
    "\n",
    "    # running with optimal lambda for ridge \n",
    "    ridge = Ridge(alpha=optimal_lam_ridge)\n",
    "    ridge.fit(X_train_transform, y_train) \n",
    "    y_test_predict = ridge.predict(X_test_transform)\n",
    "    mse = mean_squared_error(y_test,y_test_predict)\n",
    "    optimal_ridges.append(mse)\n",
    "    print ('mse for ridge regression with optimal lambda %f : %f'%(optimal_lam_ridge,mse))\n",
    "\n",
    "    # running with optimal lambda for lasso \n",
    "    lasso = Lasso(alpha=optimal_lam_lasso)\n",
    "    lasso.fit(X_train_transform, y_train) \n",
    "    y_test_predict = lasso.predict(X_test_transform)\n",
    "    mse = mean_squared_error(y_test,y_test_predict)\n",
    "    optimal_lassos.append(mse)\n",
    "    print ('mse for lasso regression with optimal lambda %f : %f'%(optimal_lam_lasso,mse))\n",
    "\n",
    "\n",
    "print ('optimal for ridge is degre %d with mse %f'%(poly_degrees[optimal_ridges.index(min(optimal_ridges))], min(optimal_ridges)))\n",
    "print ('optimal for lasso is degre %d with mse %f'%(poly_degrees[optimal_lassos.index(min(optimal_lassos))],min(optimal_lassos)))\n",
    "# Plotting ... \n",
    "#    %matplotlib inline\n",
    "#    ax = plt.gca()\n",
    "\n",
    "#    ax.plot(lambda_list, coefs_ridge)\n",
    "#    ax.set_xscale('log')\n",
    "#    ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "#    plt.xlabel('alpha')\n",
    "#    plt.ylabel('weights')\n",
    "#    plt.title('Ridge coefficients as a function of the regularization')\n",
    "#    plt.axis('tight')\n",
    "#    plt.show()\n",
    "\n",
    "#    %matplotlib inline\n",
    "#    ax2 = plt.gca()\n",
    "#    ax2.plot(lambda_list, coefs_lasso)\n",
    "#    ax2.set_xscale('log')\n",
    "#    ax2.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "#    plt.xlabel('alpha')\n",
    "#    plt.ylabel('weights')\n",
    "#    plt.title('Lasso coefficients as a function of the regularization')\n",
    "#    plt.axis('tight')\n",
    "#    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "According to the Results, per the combinations tried, the optimal configuration for ridge regressino is degree 2 with lambda 1 and the optimal configuration for lasso is degree 5 with lambda 0.01"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
